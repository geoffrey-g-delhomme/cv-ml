{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights\n",
    "\n",
    "**Convolutional Neural Networks are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner.**\n",
    "\n",
    "**Use of spatial transformers allows modules to learn invariance to translation, scale, rotation and more generic warping.**\n",
    "\n",
    "Spatial Transformer framwork can be seen as a generalisation of differentiable attention to any spatial transformation.\n",
    "\n",
    "## Spatial Transformers\n",
    "\n",
    "**Described in [notebook](../components/unitary/spatial-transformer.ipynb)**\n",
    "\n",
    "## Experiments\n",
    "\n",
    "Using a spatial transformer is an alternative way to achieve spatial invariance.\n",
    "CNN perform well due to:\n",
    "- max-pooling layers providing spatial invariance\n",
    "- convolutional layers modelling better local structure\n",
    "\n",
    "This-plate splin transformations are able to reduce the error of elastically deformed digits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
